{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "name": "assignment.ipynb",
    "colab": {
      "name": "Copy of assignment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AIkt93_FXRt"
      },
      "source": [
        "# Assignment: Classifying Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "Fz7atnqeFXRy"
      },
      "source": [
        "## Crosstraining\n",
        "\n",
        "Test how well your model, when trained on one dataset, performs on the other.\n",
        "\n",
        "The idea is to consider the situation where you have labels for one context, but not for the other. So you must train your model your \"source context\" and hope it generalizes well to your \"target context\", where you have no labels!\n",
        "\n",
        "Use the two datasets available in `sentiment/yelp.csv` (online restaurant reviews from Yelp) and `sentiment/movies.csv` (online movie reviews from IMDB). Both have a column called `text` with the text of the review and a column called `positive` which should be your outcome. No other variables are needed.\n",
        "\n",
        "To do this, make sure that you: \n",
        "\n",
        "1. You perform the \"fitting\" of both the vectorizer and the model on one of the sets\n",
        "2. Use the \"transform\" of the vectorizer to transform the second dataset into the same feature space (X) that your model was trained on. \n",
        "3. Use the \"predict\" of your model to see how well it did on the second dataset. \n",
        "\n",
        "How well does your model generalize from one to the other? What does this say about \"sentiment\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_ydOCtRFXRz"
      },
      "source": [
        "## Crosstraining 2\n",
        "\n",
        "Try to improve your transfer score using the unlabelled target data, P(X). What could you learn from the target context (without using the labels, only from the X) that might help you when training your model on your source context? How can you construct a feature space in your source context that generalizes better? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z60sxr2pODWM"
      },
      "source": [
        "\n",
        "\n",
        "> ***Crosstraining 1 & 2 just try to show improvement in score, the ultimate model is in the Ultimate model section ***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj_OxSAxuFbw"
      },
      "source": [
        "# Import Data & Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UClxOo3zd7SI"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YIsk-d23cTG",
        "outputId": "3c928ee9-f943-4b7d-fef6-f3666dc35734"
      },
      "source": [
        "# Run this if running in Google Collab\n",
        "# Mount google drive if running from Google Collab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set current directory if running from Google Collab\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')# here use your path to current notebook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BadU4zLu38lF"
      },
      "source": [
        "#import auxiliar functions\n",
        "import os,sys,inspect\n",
        "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
        "parentdir = os.path.dirname(os.path.dirname(currentdir))\n",
        "sys.path.insert(1, parentdir)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFV7h_BtuUTe"
      },
      "source": [
        "import re\n",
        "import spacy\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "# EXERCISE 4\n",
        "#\n",
        "# Prove Ng and Jordan right!!!\n",
        "\n",
        "yelps = pd.read_csv('yelps.csv').fillna(' ')\n",
        "imdb = pd.read_csv('movies.csv').fillna(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf2QhoLcKMLh"
      },
      "source": [
        "## Fixing typos in Positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "BvoMfor1I4xz",
        "outputId": "7cbdfeeb-d7a0-4d97-ddcd-47cb3a25af34"
      },
      "source": [
        "sns.countplot(yelps.positive);\n",
        "plt.title('Yelps review distribution');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rDAkluVJPuo"
      },
      "source": [
        "yelps.positive[yelps.positive == 'positive'] = 'True'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "H1HwYUqKJ7td",
        "outputId": "7b6c0149-5554-4b6b-e505-c9b4fd6d11c7"
      },
      "source": [
        "sns.countplot(imdb.positive);\n",
        "plt.title('Imdb review distribution');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x49m08pqKCSM"
      },
      "source": [
        "imdb.positive[imdb.positive == 'positive'] = 'True'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxSQbUJVKq71"
      },
      "source": [
        "Hpefully, no imbalance.\n",
        "Some values in Positive column were 'positive' instead of being 'True'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDFVwW3nGKVj"
      },
      "source": [
        "# Crosstraining1: Simple Vectorizing and logestic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDeu7SAVGNAT",
        "outputId": "b2ecda1f-527d-4e92-a51d-4dfc1a92003d"
      },
      "source": [
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "#from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "# License: BSD 3 clause\n",
        "#from pprint import pprint\n",
        "#from time import time\n",
        "#import logging\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "#lemmitizing with spacy takes to long, so we just do:\n",
        "def preprocess(X):\n",
        "  documents = []\n",
        "\n",
        "  stemmer = WordNetLemmatizer()\n",
        "  for sen in range(0, len(X)):\n",
        "    document = re.sub(r'\\W', ' ', str(X[sen])) # Remove all the special characters\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document) # remove all single characters\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)  # Remove single characters from the start\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I) # Substituting multiple spaces with single space\n",
        "    document = re.sub(r'^b\\s+', '', document) # Removing prefixed 'b'\n",
        "    document = document.lower() # Converting to Lowercase\n",
        "    document = document.split() # Lemmatization\n",
        "    document = [stemmer.lemmatize(word) for word in document]\n",
        "    document = ' '.join(document)\n",
        "    document = re.sub(r'\\b\\d+(?:\\.\\d+)?\\s+', '', document) #Removes numbers and words containing numbers\n",
        "    documents.append(document)\n",
        "  return documents\n",
        "corpus = preprocess(yelps.text)\n",
        "corpus_test = preprocess(imdb.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jGJTpu4V7tc"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df=2,\n",
        "                            max_df=.8,\n",
        "                            stop_words='english',\n",
        "                            use_idf=True,\n",
        "                            norm='l2')\n",
        "\n",
        "v = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmTmu6vrFZjt"
      },
      "source": [
        "We see that words like food, resturant, order are yelps corpus specific and won't be handy in the imdb corpus transformation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m_dBSEYYASi",
        "outputId": "2a43e942-c613-4f86-a047-207e1df69c83"
      },
      "source": [
        "y = yelps.positive \n",
        "model = LogisticRegression().fit(v, y)\n",
        "score = model.score(v, y)\n",
        "print(f'score for train data: {score}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score for train data: 0.9673209803705889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC-jH9AwafUG",
        "outputId": "3e73b495-fce7-4fb7-dbaf-c1f97448e9f7"
      },
      "source": [
        "v_test = vectorizer.transform(corpus_test)\n",
        "y_test = imdb.positive \n",
        "score = model.score(v_test, y_test)\n",
        "print(f'score for test data: {score}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score for test data: 0.7971921684698918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geXvh8ERhXNV"
      },
      "source": [
        "***Conclusion: Obviously, jumping into making a vectorizer and running a logestic regression will end up better fit (Probably overfit) on the train data and underpreform on the test data. We need to do the following as a better approach: ***\n",
        "\n",
        "1.   We need to find common words to train our model since we have datasets that are in different areas. (Done by passing the vectorizer.vocabulary_)\n",
        "2.   We need to try different vectorizers and classifiers. (Making pipelines)\n",
        "3.   We need some hyperparameter tuining. (Using gridsearchcv on the pipelines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vfeLPMs_uYp"
      },
      "source": [
        "#Crosstraining2: Using best model and transform by test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT4PWh8cHACJ"
      },
      "source": [
        "vocab1 = vectorizer.vocabulary_\n",
        "vectorizer_test = TfidfVectorizer(min_df=2,\n",
        "                            max_df=0.8,\n",
        "                            stop_words='english',\n",
        "                            use_idf=True,\n",
        "                            norm='l2',\n",
        "                            vocabulary = vocab1)\n",
        "v_test = vectorizer_test.fit_transform(corpus_test)\n",
        "vocab2 = vectorizer_test.vocabulary_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOPcytMnJwzT",
        "outputId": "e29b9a26-34a8-4325-e418-883c6239d5d5"
      },
      "source": [
        "score = model.score(v_test, y_test)\n",
        "print(f'score for test data: {score}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score for test data: 0.7641941483510989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-2cwrprKqEn"
      },
      "source": [
        "Since we transformed test data using vocabulary fron train data, the score did not improve. The best way to improve this is to tokenize(vectorize) using both datasets and then train the model on train data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_itU0T1LDsO",
        "outputId": "70370085-fca9-4703-9764-1d3a142db264"
      },
      "source": [
        "ult_vectorizer = TfidfVectorizer(min_df=2,\n",
        "                            max_df=0.8,\n",
        "                            stop_words='english',\n",
        "                            use_idf=True,\n",
        "                            norm='l2',)\n",
        "ult_corpus = corpus+corpus_test\n",
        "ult_vectorizer.fit(ult_corpus)    #Unsupervise vectorizer for both data sets\n",
        "v_test_ult = ult_vectorizer.transform(corpus_test)\n",
        "v_train_ult = ult_vectorizer.transform(corpus)\n",
        "model_ult = LogisticRegression().fit(v_train_ult, y) # supervised model just on the training data\n",
        "score = model_ult.score(v_train_ult, y)\n",
        "print(f'score for train data: {score}')\n",
        "score = model_ult.score(v_test_ult, y_test) #improved score\n",
        "print(f'score for test data: {score}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score for train data: 0.9669809905702829\n",
            "score for test data: 0.7957522548647081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia47y2h7OtvD"
      },
      "source": [
        "We see that under Ceteris paribus score for test data improves only when we combine two data sets for vectorizing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZRUdwacPNoI"
      },
      "source": [
        "# Ultimate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq_sCHDsPQDI"
      },
      "source": [
        "We can test different feature extraction methods and different classifiers to improve fitting and we can tune hyperparameters. Since running pipelines with different classifiers takes a lot of time, we just tune hyperparameters for Tfidfvectorizer and LogesticRegression here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYR2A6spPyox",
        "outputId": "56724d43-5c7d-4d00-9c1e-fb0854138da7"
      },
      "source": [
        "# Pipeline & Gridsearch setup\n",
        "# TFIDF pipeline setup\n",
        "tvc_pipe = Pipeline([\n",
        " ('tvec', TfidfVectorizer()),\n",
        " ('lr', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Setting params for TFIDF Vectorizer gridsearch\n",
        "tf_params = {\n",
        " 'tvec__min_df':[10],\n",
        " 'tvec__max_df': [0.8],\n",
        " 'tvec__norm': ['l2'],\n",
        " 'tvec__use_idf': [True],\n",
        " 'lr__penalty': ['l2'],\n",
        " 'lr__solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Setting up GridSearch for TFIDFVectorizer\n",
        "tvc_gs = GridSearchCV(tvc_pipe, param_grid=tf_params, cv = 5, verbose =1, n_jobs = 100)\n",
        "tvc_gs.fit(corpus, y)\n",
        "# Scoring Training data on TFIDFVectorizer\n",
        "print(f'score for train data: {tvc_gs.score(corpus, y)}')\n",
        "# Scoring Test data on TFIDFVectorizer\n",
        "print(f'score for test data: {tvc_gs.score(corpus_test, y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=100)]: Using backend LokyBackend with 100 concurrent workers.\n",
            "[Parallel(n_jobs=100)]: Done   2 out of 100 | elapsed:   52.0s remaining: 42.5min\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=100)]: Done 100 out of 100 | elapsed: 21.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score for train data: 0.9713108606741798\n",
            "score for test data: 0.800811951282923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjDrm2ZCXOsr",
        "outputId": "34226e47-8b74-4b16-fffe-34c6f4630893"
      },
      "source": [
        "tvc_gs.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tvec',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=0.8, max_features=None,\n",
              "                                 min_df=10, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('lr',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dcgltXJYRfr"
      },
      "source": [
        "Since the fits increase exponentially (2^n), I have used Gridsearchcv with 5 folds multiple times and each time chosed the best params, however, I know that this does not cover all the possible fits and thus may not contain the optimal fit:\n",
        "\n",
        "***1st:*** test score=0.8007\n",
        "\n",
        " 'tvec__min_df':[0.05, 0.01, 2, 10],\n",
        "\n",
        " 'tvec__max_df': [0.9, 0.8],\n",
        "\n",
        "***2nd:*** test score=0.8007\n",
        "\n",
        " 'tvec__min_df':[10,20,50],\n",
        "\n",
        " 'tvec__max_df': [0.8,0.85,0.75],\n",
        "\n",
        " ***3ed:*** test score=0.8007\n",
        "\n",
        "  'tvec__norm': ['l1', 'l2'],\n",
        "\n",
        " 'tvec__use_idf': [True, False],\n",
        "\n",
        " ***4th:*** test score=0.8008\n",
        "\n",
        "  'lr__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "\n",
        "\n",
        " 'lr__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_tf30QAoZba"
      },
      "source": [
        "It seems that the score can change only if we change the classifier, preprocessing, and tokenizer."
      ]
    }
  ]
}